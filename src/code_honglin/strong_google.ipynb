{"cells":[{"cell_type":"markdown","source":["#Packages"],"metadata":{"id":"Iew8f6Cl7n-w"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import math\n","import random\n","import multiprocessing as mp"],"metadata":{"id":"B7PDV0_M7naX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Create Google's culture\n","\n","-- no need to rerun"],"metadata":{"id":"xTnaGzjl7eYm"}},{"cell_type":"code","source":["mean = 2\n","sd = 0.1\n","len_google = 6\n","employee = 30\n","num_repeats = 10\n","\n","single_sample = np.random.normal(mean, sd, len_google * employee )\n","data = list(np.tile(single_sample, num_repeats))\n","#print(*data, sep='\\n')\n","#this is for initializing Google's culture (180 people for 10 initial conditions\n","#in the simulation it indicates firms 0-5\n","#for other variables of employees in Google, we just keep them as the input file for Model 1"],"metadata":{"id":"P9ke7v978OQX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Simulation Model"],"metadata":{"id":"VRvzasVQ7jQz"}},{"cell_type":"code","source":["n_processes = 5  # Number of runs you want to parallelize per group\n","n_groups = 2  # Number of groups you want to parallelize the whole input, should be one from 10/5/2 because we have 10 input conditions\n","\n","def simulation(args):\n","  group, run_id = args\n","  random.seed(run_id)\n","  np.random.seed(run_id)\n","\n","  ### parameters that will be varied----------------------------------------------\n","  r1list = (0.1, .2, .3,.4,.5,.6,.7,.8,.9, 1) #varying r1 of other firms\n","  s1list = (0.1, .2, .3,.4,.5,.6,.7,.8,.9,1, 1.1, 1.2, 1.3, 1.4, 1.5) #varying s1 of other firms\n","  b1list = (0, 0.1, .2, .3,.4,.5,.6,.7,.8,.9, 1) #varying b1 of other firms\n","  s0list = (0.03, ) # base rate of random entry. hiring parameters, s0=1 corresponds to simulating isolated firms\n","  r0list = (0.05, ) # corresponding to high/low industry turnover conditions\n","  r1_google_list = (.3, 1) #google's r1\n","  b1_google_list = (.1,.7) #google's b1\n","  s1_google_list = (.3, 1) #google's s1\n","\n","  ### Set global parameters for simulations\n","  employee = 30 # default number of employees per firm\n","  fm_no = 30    # default number of firms (will merge the first six later)\n","  time = 120    # number of time periods (months)\n","  var_win = 0.1 # which within variance in the input data?\n","\n","  # departure parameters\n","  r0=0.03 # turnover base rate (3.5% monthly according to JOLTS)\n","  r2=0.05 # max increase in turnover probability\n","\n","  # socialization parameters\n","  b0=0\n","  b2=.3 # speed of socialization susceptibility decline by tenure\n","  b3=.1 # speed of socialization susceptibility decline by prior employments\n","\n","  google_set =[0,1,2,3,4,5] #this is for merging the first six firms as Google (180 people)\n","\n","  input = 'initial_conditions_strong_culture_big_google.csv'\n","  output = f'output_data_group_{group}_run_{run_id}.csv'\n","  #add date automatically\n","\n","  data=[] # a big table for results\n","\n","  # Load the entire CSV file\n","  df_all = pd.read_csv(input)\n","\n","  # Filter rows\n","  filtered_df = df_all[df_all['var_win'] == var_win]\n","\n","  # Calculate the number of units and split into groups\n","  # Process each unit of 900 people (30*30)\n","  num_units = len(filtered_df) // int(employee * fm_no)\n","  units_per_group = num_units // n_groups\n","  group_units = range(group * units_per_group, (group + 1) * units_per_group)\n","\n","  # Loop over different initial conditions--------------------------------------\n","  for unit in group_units:\n","\n","    start_row = unit * int(employee * fm_no)\n","    end_row = (unit + 1) * int(employee * fm_no)\n","    df_unit = filtered_df.iloc[start_row:end_row]\n","\n","    # Extract updating variables from selected initial condition\n","    culture = list(df_unit['culture'])\n","    tenure = list(df_unit['tenure'])\n","    employments = list(df_unit['employments'])\n","\n","    # Loop over different parameters -------------------------------------------\n","    for s0 in s0list:\n","      for r0 in r0list:\n","        for r1_default in r1list:\n","          for b1_default in b1list:\n","            for s1_default in s1list:\n","              for r1 in r1_google_list:\n","                for b1 in b1_google_list:\n","                  for s1 in s1_google_list:\n","\n","                    ### REORG VARIABLES\n","                    # c_all, t_all, e_all (or e_all copy): three 30*30 list of lists (~tables)\n","                    # row is for a firm\n","                    # column is for an employee in a firm\n","\n","                    # employees in different firms and their cultural scores\n","                    c_all=[]\n","                    for i in range(fm_no):\n","                      c_firm = culture[i*employee: (i+1)*employee]\n","                      c_all.append(c_firm)\n","\n","                    # firm culture is calculated as the median of its employeesâ€™ cultural scores\n","                    firm_culture =[]\n","                    for i in range(fm_no):\n","                      if ((i in google_set) ==True):\n","                        temp = sum(c_all[:len(google_set)], [])\n","                        firm_culture.append(np.median(temp)) # here merge the first six as the big \"Google\"\n","                        # and the big Google's median culture as Google culture\n","                      else:\n","                        firm_culture.append(np.median(c_all[i]))\n","\n","                    # tenure\n","                    t_all=[]\n","                    for i in range(fm_no):\n","                      t_firm = tenure[i*employee: (i+1)*employee]\n","                      t_all.append(t_firm)\n","\n","                    # prior employments\n","                    e_all=[]\n","                    for i in range(fm_no):\n","                      e_firm = employments[i*employee: (i+1)*employee]\n","                      e_all.append(e_firm)\n","                    e_all_copy = e_all.copy()# used for recording update\n","\n","                    initial_firm0 =  firm_culture[0] #No.0-5 firms as the merged firm sharing identical culture\n","                    initial_other = np.mean(firm_culture[len(google_set):]) # initial others' culture\n","                    # use the mean of the other 24 firms' cultures to record the changing trend\n","                    # how they converge to Google's culture and vice versa\n","\n","                    # initialize additional variables\n","                    ave_hire_list=[] # ave hire proportion\n","                    carrier_list=[]  # ave carrier proportion\n","                    frac_googlers_list =[] #rehire from google for other firms\n","                    frac_g_hire_others_list =[] #rehire from other firms for google\n","\n","            #------------------loop over months---------------------------------\n","                    for t in range(time):\n","\n","            #------------------loop over firms----------------------------------\n","                      for i in range(fm_no):\n","                        if ((i in google_set) == True):\n","                          temp = sum(c_all[:len(google_set)], [])\n","                          firm_culture.append(np.median(temp)) # google culture\n","                        else:\n","                          firm_culture.append(np.median(c_all[i]))#others' culture\n","                          # update firm culture, always, for every round of simulation\n","                          # this impacts all following processes\n","\n","            #-----------departure-----------------------------------------------\n","                      dps =[] # the list of departure probability lists for firms\n","\n","                      for i in range(fm_no):\n","                        #defult values for other firms\n","                        firm_r1 = r1_default\n","                        if ((i in google_set) == True):  # For firm_0 (Google)\n","                        #a lower turnover\n","                          firm_r1 = r1\n","\n","                        dp =[] #departure probability for every step, every person in a single firm\n","                        for j in range(employee):\n","                          dp.append(random.random() > ((r0+r2) - r2* math.exp(-(((firm_culture[i] - c_all[i][j])**2)/(2* firm_r1 *firm_r1 ))))) #the equation 4\n","                        dps.append(dp)\n","                      for i in range(fm_no):\n","                        for j in range(employee):\n","                          if(dps[i][j] == True):\n","                            t_all[i][j] = t_all[i][j]+1\n","                            #do not update employee value here because you don't know if she will be rehired or not\n","\n","                      #who will leave?\n","                      #the pool of available indexes and their culture scores for each firm\n","                      index0=[] # to track persons (index) who will leave\n","                      available=[] #available pool of (departure) culture scores for each firm\n","                      for i in range(fm_no):\n","                        index_temp=[]\n","                        ava_temp=[]\n","                        for j in range(employee):\n","                          if (dps[i][j] == False):\n","                            index_temp.append(j)\n","                            ava_temp.append(c_all[i][j])\n","                        index0.append(index_temp)\n","                        available.append(ava_temp)\n","\n","                      #remove departure employees from the firm\n","                      for i in range(fm_no):\n","                        c_all[i] = list(np.delete(c_all[i], index0[i]))\n","                        t_all[i] = list(np.delete(t_all[i], index0[i]))\n","                        e_all_copy[i] = list(np.delete(e_all_copy[i], index0[i]))\n","\n","            #-----------recruitment---------------------------------------------\n","                      # initialize average mobility\n","                      carriers=0\n","                      googler=0\n","                      g_hire_others=0\n","\n","                      count=[]\n","                      for i in range(fm_no):\n","                        count.append(len(available[i]))\n","\n","                      google_turnover = sum(count[:len(google_set)])\n","                      others_turnover = sum(count[len(google_set):])\n","\n","                      ave_hire = (np.sum(count)  / (employee * fm_no))\n","\n","                      random_order = []\n","                      for i in range(len(count)):\n","                        repeat = [[i] * count[i]]\n","                        random_order += repeat\n","\n","                      overall=[]\n","                      for i in range(len(random_order)):\n","                        for j in range(len(random_order[i])):\n","                          overall.append(random_order[i][j])\n","                      random.shuffle(overall) # slot-based randomization\n","\n","                      for q in range(len(overall)):\n","                        i = overall[q]\n","                        firm_s1 = s1_default\n","                        #defult values for other firms\n","                        if ((i in google_set) == True):  # For firm_0 (Google)\n","                        #a lower bandwidth for hiring\n","                          firm_s1 = s1\n","\n","                        other_cul=[]\n","                        other_index =[]\n","                        for k in range(fm_no):\n","                          if ((i in google_set) == False):\n","                            if ((k == i) ==False):\n","                              other_cul.append(available[k][:])\n","                              convert_list = sum(len(index0[i]) for i in range(k))\n","                              other_index.append([item + convert_list for item in index0[k]]) #others' index\n","                          else:\n","                            if ((k in google_set) ==False):\n","                              other_cul.append(available[k][:])\n","                              convert_list = sum(len(index0[i]) for i in range(k))\n","                              other_index.append([item + convert_list for item in index0[k]]) #others' index\n","                        #you only consider hiring an employee from other firms\n","\n","                        for u in range(1, len(other_cul)):\n","                          other_cul[0] = np.append(other_cul[0], other_cul[u])\n","                          other_index[0] = np.append(other_index[0], other_index[u])\n","                        other_cul = (list(other_cul[0])).copy()\n","                        other_index = (list(other_index[0])).copy()\n","\n","                        others_c = []\n","                        others_index=[]\n","                        for n in range(len(other_cul)):\n","                            if abs((firm_culture[i]) - (other_cul[n])) < 2 * firm_s1:\n","                                others_c.append(other_cul[n])\n","                                others_index.append(other_index[n])\n","\n","            #----recruitment from external sources------------------------------\n","                        if((random.random() < s0) or (len(others_c) ==0) ):\n","                          #new employee\n","                          new = np.random.normal(firm_culture[i], firm_s1, 1)\n","                          t_all[i] = list(np.append(t_all[i] , [0]))\n","                          c_all[i] = list(np.append(c_all[i] , new))\n","                          e_all_copy[i]  = list(np.append(e_all_copy[i] , [1]))\n","\n","            #----recruitment from the available pool----------------------------\n","                        else: # already checked that at least one exists\n","                          carriers= carriers+1\n","                          v=list(random.sample(others_c, 1))\n","                          hire_index = others_index[others_c.index(v[0])]\n","\n","                          if ((i in google_set) == True): # if firm hiring is Google\n","                              g_hire_others = g_hire_others+1\n","                          else: # if firm hiring is other\n","                            if (( hire_index in list(range(len(google_set * employee)))) == True): # if emp hired is from Google\n","                              googler = googler+1\n","\n","                          c_all[i] =  list(np.append(c_all[i] , v))\n","                          t_all[i] = list( np.append(t_all[i] , [0]))\n","                          for a in range(fm_no):\n","                            for b in range(len(available[a])):\n","                              if (v[0] == available[a][b]):\n","                                value =index0[a][b]\n","                                e_all_copy[i] = list( np.append(e_all_copy[i] , [e_all[a][value]+1]))\n","\n","            #----socialization--------------------------------------------------\n","                      for i in range(fm_no):\n","                        #defult values for other firms\n","                        firm_b1 = b1_default\n","                        if ((i in google_set) == True):  # For firm_0 (Google)\n","                        #a higher socialization\n","                          firm_b1 = b1\n","                        for j in range(len(c_all[i])):\n","                          c_all[i][j] = c_all[i][j] + ( firm_culture[i] -c_all[i][j] )* (firm_b1* math.exp(- b2* (t_all[i][j] -1) -b3* (e_all_copy[i][j] -1)) +b0) #the equation 5\n","\n","                      # after updating employments, save e_all and copy() for next period\n","                      e_all = e_all_copy.copy() # don't overwrite\n","                      e_all_copy = e_all.copy()\n","\n","                      # store average hires and carries per time period\n","                      ave_hire_list.append(ave_hire)\n","                      carrier_list.append(carriers/np.sum(count))\n","                      frac_googlers_list.append(googler / others_turnover)\n","                      frac_g_hire_others_list.append(g_hire_others / google_turnover if google_turnover!=0 else 0) #an extreme condition that no one leaves google\n","\n","                    turnover_average =np.mean(ave_hire_list)\n","                    carriers_average = np.mean(carrier_list)\n","                    frac_googlers_average = np.mean(frac_googlers_list)\n","                    frac_g_hire_others_average = np.mean(frac_g_hire_others_list)\n","\n","        #----keep data ---------------------------------------------------------\n","                    data.append({\n","                                    'initcond': unit,\n","                                    's0': s0,\n","                                    'r0': r0,\n","                                    'r1_other': r1_default,\n","                                    'b1_other': b1_default,\n","                                    's1_other': s1_default,\n","                                    'r1_google': r1,\n","                                    'b1_google': b1,\n","                                    's1_google': s1,\n","                                    'tenure_google': np.mean(list(sum(t_all[:len(google_set)], []))),\n","                                    'tenure_others': sum([np.mean(t_all[i]) for i in range(len(google_set), int(fm_no))])/int(fm_no - len(google_set)),\n","                                    'employment_google': np.mean(list(sum(e_all[:len(google_set)], []))),\n","                                    'employment_others': sum([np.mean(e_all[i]) for i in range(len(google_set), int(fm_no))])/int(fm_no - len(google_set)),\n","                                    'turnover': turnover_average,\n","                                    'carriers': carriers_average,\n","                                    'google_culture_change':np.median(list(sum(c_all[:len(google_set)], []))) - initial_firm0,\n","                                    'other_culture_change': np.mean(firm_culture[len(google_set):] ) - initial_other,\n","                                    'googlers_to_other_firms': frac_googlers_average,\n","                                    'others_to_google': frac_g_hire_others_average\n","                                })\n","\n","  df = pd.DataFrame(data)\n","  df.to_csv(output, index=False)\n","  return f\"Group {group}, Run {run_id} completed.\"\n","\n","\n","#----parallelize----------------------------------------------------------------\n","def main():\n","    # Create a list of tuples (group, run_id) for each combination of group and run\n","    tasks = [(group, run_id) for group in range(n_groups) for run_id in range(n_processes)]\n","\n","    with mp.Pool(n_processes * n_groups) as pool:\n","        results = pool.map(simulation, tasks)\n","    print(results)\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"id":"xZ35S6nWEMsQ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/pro.ipynb","timestamp":1693336589211}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}